{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "899c0105",
   "metadata": {},
   "source": [
    "# Original Eigengame "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "862ec350",
   "metadata": {},
   "source": [
    "### 1- Sequential Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9591965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "\n",
    "# generate random matrix X \n",
    "X = np.ceil(np.random.normal(50,4, size= (100, 100)))\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fde0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Changes: \n",
    "- array 100x100\n",
    "- for v initial randomly generate a vector \n",
    "- take away for loop for i \n",
    "- rewards = matrix multiplication\n",
    "- compute gradient manually**\n",
    "- implement ui based on equation 6 and 7\n",
    "- fix t for loop --> ceiling\n",
    "- check multiplication\n",
    "'''\n",
    "\n",
    "# a = alpha = step size\n",
    "a = 0.01\n",
    "# p = max error tolerance\n",
    "p = 0.000001\n",
    "# vo initial as a randomly generated vector with same dimmension as matrix\n",
    "#vi = np.random.random(100)\n",
    "vi = np.random.normal(5,1.5, size= (1, 100))\n",
    "vo = vi\n",
    "# utility gradient (equation 7) \n",
    "ui = 2 * X.T * (np.dot(vi, X))\n",
    "minimum = min((la.norm(ui))/2,p)\n",
    "ti = int(np.ceil(5/4 * pow(minimum,-2)))\n",
    "r = []\n",
    "\n",
    "for t in range(1, ti):\n",
    "    Xvi = np.dot(vi, X)\n",
    "    rewards = Xvi\n",
    "    penalties = 0\n",
    "    # no penalty for first iteration bc no vj (previous vectors)\n",
    "    if np.array_equal(vi,vo):\n",
    "        r[0] = vi\n",
    "        penalties = 0\n",
    "    else:\n",
    "        #print(np.inner((X * vi),(X * vj)))\n",
    "        #print(np.inner((X * vj),(X * vj)))\n",
    "        for i in range(1, len(r)):\n",
    "            vj = r[i]\n",
    "            Xvj = np.dot(vj, X)\n",
    "            penalties += (((np.inner(Xvi, Xvj))/(np.inner(Xvj, Xvj))) * Xvj)\n",
    "        Xvj = np.dot(vj, X)\n",
    "        penalties += (((np.inner(Xvi, Xvj))/(np.inner(Xvj, Xvj))) * Xvj)\n",
    "\n",
    "    grad_vi = 2 * X.T * (rewards - penalties)\n",
    "    grad_R_vi = grad_vi - ((np.inner(grad_vi, vi))* vi)\n",
    "    # grad_R_vi = grad_Vi - ((grad_vi @ vi)* vi)\n",
    "    der_vi = vi + (a * grad_R_vi)\n",
    "    #print('M')\n",
    "    #print(la.norm(der_vi))\n",
    "    #print('M')\n",
    "    vi = der_vi / (la.norm(der_vi))\n",
    "    print(vi)\n",
    "    print()\n",
    "# return vi \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41416c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# selecting Column Vector\n",
    "#print(X[:,:1])\n",
    "print()\n",
    "\n",
    "# transpose fnc\n",
    "#print(X.T)\n",
    "#print(np.transpose(X))\n",
    "print()\n",
    "print()\n",
    "\n",
    "# matrix multiplication\n",
    "v1 = np.random.normal(5,1.5, size= (1, 100))\n",
    "print(np.dot(v1, X))\n",
    "print()\n",
    "print(np.matmul(v1, X))\n",
    "print()\n",
    "print(v1 @ X)\n",
    "print()\n",
    "\n",
    "print(np.inner(v1, X))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e662f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# eigenvalues, eigenvectors, norm fncs\n",
    "\n",
    "# 1st array = eigenvalues in asceding order\n",
    "# 2nd array = normalized eigenvectors corresponding to eigenvalue\n",
    "from numpy import linalg as la\n",
    "print(la.eig(X))\n",
    "print()\n",
    "print(la.norm(X))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb15cea5",
   "metadata": {},
   "source": [
    "# \n",
    "### 2- Sequential + Parallel Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28462426",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = \n",
    "# a = step size \n",
    "a = 0.01\n",
    "vi = \n",
    "T = \n",
    "\n",
    "for t in range(1,T):\n",
    "    rewards = np.dot(vi, Xt)\n",
    "    pernalties = \n",
    "    grad_vi = 2 * Xt.T * (rewards - penalties)\n",
    "    grad_R_vi = grad_vi - ((np.inner(grad_vi, vi))* vi)\n",
    "    der_vi = vi + (a * grad_R_vi)\n",
    "    vi = der_vi / (la.norm(der_vi))\n",
    "    np.broadcast(vi)\n",
    "return vi\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "abe99fd7",
   "metadata": {},
   "source": [
    "# \n",
    "# Âµ-Eigengame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c0c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
